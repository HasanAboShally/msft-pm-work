{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernel_info": {
   "name": "synapse_pyspark",
   "jupyter_kernel_name": null
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "language": null,
   "name": "synapse_pyspark"
  },
  "a365ComputeOptions": null,
  "sessionKeepAliveTimeout": 30,
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "3e67377e-5962-433c-8c2f-d796a8687c2d",
    "default_lakehouse_name": "Lakehouse_Silver",
    "default_lakehouse_workspace_id": "8e0cc78d-1667-4e88-9523-a04c1d5dd187",
    "known_lakehouses": [
     {
      "id": "3e67377e-5962-433c-8c2f-d796a8687c2d"
     },
     {
      "id": "3ad63567-2849-4e5b-9cf2-eacd059e50a5"
     }
    ]
   },
   "environment": {
    "environmentId": "99999999-9999-9999-9999-999999999999",
    "workspaceId": "8e0cc78d-1667-4e88-9523-a04c1d5dd187"
   }
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transformations: Bronze \u2192 Silver\n\nJoins t2 and t3 from Bronze to create t1 in Silver lakehouse."
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create t1 in Silver from Bronze tables\nprint(\"Creating t1 in Silver from Bronze.t2 CROSS JOIN Bronze.t3...\")\ntry:\n    spark.sql(\"\"\"\n        CREATE OR REPLACE TABLE dbo.t1 USING DELTA AS (\n            SELECT * FROM Lakehouse_Bronze.dbo.t2\n            CROSS JOIN Lakehouse_Bronze.dbo.t3\n            LIMIT 10000\n        )\n    \"\"\")\n    print(\"t1 created successfully!\")\nexcept Exception as e:\n    print(f\"ERROR creating t1: {e}\")\n    import traceback\n    traceback.print_exc()\n    raise\n"
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Optimize t1\nprint(\"Running OPTIMIZE dbo.t1 VORDER...\")\ntry:\n    spark.sql(\"OPTIMIZE dbo.t1 VORDER\")\n    print(\"OPTIMIZE complete!\")\nexcept Exception as e:\n    print(f\"OPTIMIZE failed (non-fatal): {e}\")\n"
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify the join result\ncnt = spark.sql(\"SELECT count(*) as total_rows FROM dbo.t1\").collect()[0][\"total_rows\"]\nprint(f\"t1 total rows: {cnt}\")\n"
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}