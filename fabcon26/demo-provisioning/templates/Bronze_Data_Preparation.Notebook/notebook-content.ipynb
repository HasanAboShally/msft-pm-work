{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernel_info": {
   "name": "synapse_pyspark",
   "jupyter_kernel_name": null
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "language": null,
   "name": "synapse_pyspark"
  },
  "a365ComputeOptions": null,
  "sessionKeepAliveTimeout": 30,
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "3ad63567-2849-4e5b-9cf2-eacd059e50a5",
    "default_lakehouse_name": "Lakehouse_Bronze",
    "default_lakehouse_workspace_id": "8e0cc78d-1667-4e88-9523-a04c1d5dd187",
    "known_lakehouses": [
     {
      "id": "3ad63567-2849-4e5b-9cf2-eacd059e50a5"
     }
    ]
   },
   "environment": {
    "environmentId": "99999999-9999-9999-9999-999999999999",
    "workspaceId": "8e0cc78d-1667-4e88-9523-a04c1d5dd187"
   }
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dev/Test/Prod data set simulation in a Bronze layer\n\nCreates t3_dev (1% sample), t3_test (10% sample), and t3 (alias of t3_dev) from t3_prod.\nAlso ensures t2 (diabetes) data is available for downstream Transformations notebook."
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Self-healing data load: ensure tables exist (copy job fallback)\nimport traceback\n\nBLOB_T3_PROD = \"wasbs://holidaydatacontainer@azureopendatastorage.blob.core.windows.net/Processed/\"\nBLOB_T2 = \"wasbs://mlsamples@azureopendatastorage.blob.core.windows.net/diabetes/\"\n\ndef table_exists(name):\n    \"\"\"Check if a table exists in the default lakehouse.\"\"\"\n    try:\n        spark.table(name).limit(1).collect()\n        return True\n    except Exception:\n        return False\n\nprint(\"=== Checking Bronze lakehouse tables ===\")\n\n# Check and load t3_prod\nif table_exists(\"t3_prod\"):\n    print(\"  t3_prod: EXISTS (from copy job)\")\nelse:\n    print(\"  t3_prod: MISSING \u2014 loading from public blob storage...\")\n    try:\n        df = spark.read.parquet(BLOB_T3_PROD)\n        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"t3_prod\")\n        print(f\"  t3_prod: LOADED ({df.count()} rows)\")\n    except Exception as e:\n        print(f\"  t3_prod: LOAD FAILED \u2014 {e}\")\n        traceback.print_exc()\n\n# Check and load t2\nif table_exists(\"t2\"):\n    print(\"  t2: EXISTS (from copy job)\")\nelse:\n    print(\"  t2: MISSING \u2014 loading from public blob storage...\")\n    try:\n        df = spark.read.parquet(BLOB_T2)\n        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"t2\")\n        print(f\"  t2: LOADED ({df.count()} rows)\")\n    except Exception as e:\n        print(f\"  t2: LOAD FAILED \u2014 {e}\")\n        traceback.print_exc()\n\nprint(\"=== Data availability check complete ===\")\n"
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create derivative Bronze tables from t3_prod\nprint(\"Reading t3_prod...\")\nt3_prod_df = spark.table(\"t3_prod\")\nprod_count = t3_prod_df.count()\nprint(f\"t3_prod row count: {prod_count}\")\n\nprint(\"Creating t3_dev (1% sample)...\")\nt3_prod_df.sample(fraction=0.01, seed=42).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"t3_dev\")\n\nprint(\"Creating t3_test (10% sample)...\")\nt3_prod_df.sample(fraction=0.10, seed=123).write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"t3_test\")\n\nprint(\"Creating t3 from t3_dev...\")\nspark.table(\"t3_dev\").write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"t3\")\n\nprint(\"All Bronze derivative tables created successfully!\")\n"
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify all table row counts\nfor tbl in [\"t3_prod\", \"t3_dev\", \"t3_test\", \"t3\", \"t2\"]:\n    try:\n        cnt = spark.table(tbl).count()\n        print(f\"  {tbl}: {cnt} rows\")\n    except Exception as e:\n        print(f\"  {tbl}: ERROR \u2014 {e}\")\nprint(\"Bronze layer verification complete.\")\n"
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}