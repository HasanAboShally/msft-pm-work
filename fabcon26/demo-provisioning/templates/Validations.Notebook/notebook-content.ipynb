{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernel_info": {
   "name": "synapse_pyspark",
   "jupyter_kernel_name": null
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "language": null,
   "name": "synapse_pyspark"
  },
  "a365ComputeOptions": null,
  "sessionKeepAliveTimeout": 30,
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "3e67377e-5962-433c-8c2f-d796a8687c2d",
    "default_lakehouse_name": "Lakehouse_Silver",
    "default_lakehouse_workspace_id": "8e0cc78d-1667-4e88-9523-a04c1d5dd187",
    "known_lakehouses": [
     {
      "id": "3e67377e-5962-433c-8c2f-d796a8687c2d"
     },
     {
      "id": "3ad63567-2849-4e5b-9cf2-eacd059e50a5"
     }
    ]
   },
   "environment": {
    "environmentId": "99999999-9999-9999-9999-999999999999",
    "workspaceId": "8e0cc78d-1667-4e88-9523-a04c1d5dd187"
   }
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Validations\n\nValidates data across Bronze and Silver lakehouses."
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Validate all tables across Bronze and Silver lakehouses\nprint(\"=== Data Validation Report ===\")\nprint()\n\nvalidations = [\n    (\"Bronze t3 (row count)\", \"SELECT count(*) as cnt FROM Lakehouse_Bronze.dbo.t3\"),\n    (\"Bronze t3 (by country)\", \"SELECT countryOrRegion, count(1) as cnt FROM Lakehouse_Bronze.dbo.t3 GROUP BY countryOrRegion\"),\n    (\"Bronze t2 (row count)\", \"SELECT count(*) as cnt FROM Lakehouse_Bronze.dbo.t2\"),\n    (\"Silver t1 (row count)\", \"SELECT count(*) as cnt FROM dbo.t1\"),\n]\n\nall_passed = True\nfor name, query in validations:\n    try:\n        result = spark.sql(query)\n        print(f\"\u2705 {name}:\")\n        result.show(truncate=False)\n    except Exception as e:\n        print(f\"\u274c {name}: FAILED \u2014 {e}\")\n        all_passed = False\n\nprint()\nif all_passed:\n    print(\"=== ALL VALIDATIONS PASSED ===\")\nelse:\n    print(\"=== SOME VALIDATIONS FAILED ===\")\n"
   ],
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
